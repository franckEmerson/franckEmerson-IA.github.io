<!DOCTYPE html>

<html>
	<head>
		<title>UN ESSAI</title>
	</head>
	<body>
		<h1>LES DILEMMES ETHIQUES DE LA VOITURE AUTONOME</h1>
		
		<p>Dans une situation d’accident, les éventuelles voitures<br>
			autonomes devront-elles protéger leur passager ou éviter l’enfant qui traverse la rue?<br>
			<br>Une équipe internationale de chercheurs a recueilli les<br>préférences de deux millions de personnes à travers une<br>
			plateforme en ligne. Mais cette étude montre trop de limites<br>pour être conclusive.
			<br><br><strong>Franck Emerson, le 8/5/2020</strong><br><br>
			
			<img src="https://img.aws.la-croix.com/2018/10/26/1200978862/navette-autonome-Navya-centre-recherches-developpement-Valeo-20-novembre-2017-Bobigny_0_729_486.jpg"/>
		</p>
		<p>
			En cas d'accident, que doit décider l'intelligence artificielle<br>d'un futur véhicule
			autonome durant la fraction de seconde dont elle dispose:<br>  heurter un homme en
			bonne santé ou une femme ageé ?<br>Et qui est tenu pour responsable: le "conducteur" humain qui<br>
			n'a même pas touché les commandes, le fabricant de la voiture ou encore<br> <strong>l'ingénieur qui
			a programmé l'intelligence artificielle?</strong> Questions terribles,<br>on en convient.
			Pourtant, une équipe internationale de chercheurs a décidé<br> de les poser
			aux internautes du monde entier pour étudier leurs préférence morales.
		</p>
		<br>
		
		<p>
			" Jamais, dans toute l’histoire de l’humanité, nous n’avons permis à une machine de<br>
			décider seule qui doit vivre et qui doit mourir, sans supervision, rappellent les<br>
			chercheurs du Massachusetts Institute of Technology (MIT). Mais nous allons franchir<br>
			ce cap bientôt ; et cela (…) va arriver dans un des aspects les plus terre à terre de<br> notre quotidien : les transports. "<br><br>
			Pour ces scientifiques, il est temps que les citoyens fassent connaître leurs préférences<br>aux
			industriels chargés d’élaborer les algorithmes d’éventuelles voitures autonomes.<br>
			Pour sonder le point de vue de la population mondiale, ils ont mis en place une<br>
			 plate-forme en ligne baptisée " <a href="http://moralmachine.mit.edu/"> "Moral Machine "</a>,qui enregistre les choix des<br>
			 participants face à différents scénarios à l’issue fatale, à partir de neuf variables.<br>
			 Au final, 26 millions de possibilités. Les internautes doivent trancher sur 13 cas concrets.<br>
			 L’outil est toujours accessible, mais les résultats ne seront plus pris en compte dans l’étude.<br><br>
			 
			 <img src="https://img.aws.la-croix.com/2018/10/26/1200978862/voiture_1_728_544.jpg"/>
		</p>
		<br>
		<h2>Sauver les chiens plutôt que les criminels ?</h2>
			
		<p>
			Les résultats de cette expérience, accessible depuis 2016, ont été publiés le 24 octobre <a href="https://www.nature.com/articles/s41586-018-0637-6"> dans la revue scientifique nature.</a><br>
			Premiers enseignements : les internautes préfèrent généralement sauver les humains plutôt que les animaux,<br>le plus grand nombre de vies possibles, et les plus jeunes par
			rapport aux aînés. Certains résultats sont plus…<br>
		</p>
			
		<h2>Des scénarios trop simplistes</h2>
		<p>
			Bien qu’intéressante sur nos choix moraux, l’étude et ses résultats ne manquent pas de biais que reconnaissent les auteurs.<br>
		    Dans la vie réelle, vous allez avoir plusieurs voies de circulation et plusieurs types de véhicules, des cyclistes, des motos,<br>
			  commente Nathalie Nevejans, maître de conférences à la faculté de droit de Douai.<br><br>
			  Tant de paramètres que le conducteur humain prend en compte et auxquels il s’adapte avec plus ou moins de réactivité.
			  <br>" Il faut arrêter de croire que les machines prendront toujours de meilleures décisions que les êtres humains,<br>qui peuvent considérer des éléments non accessibles à la machine. "
			
		</p>
	</body>

</html>